<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog Name</title>
  <subtitle>Blog subtitle</subtitle>
  <id>http://blog.url.com/modules</id>
  <link href="http://blog.url.com/modules"/>
  <link href="http://blog.url.com/feed.xml" rel="self"/>
  <updated>2014-09-18T20:00:00-04:00</updated>
  <author>
    <name>Blog Author</name>
  </author>
  <entry>
    <title>Save Results to File</title>
    <link rel="alternate" href="http://blog.url.com/modules/module13-save.html"/>
    <id>http://blog.url.com/modules/module13-save.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-11T20:12:51-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">
</content>
  </entry>
  <entry>
    <title>Analyzing a Subset of the Data</title>
    <link rel="alternate" href="http://blog.url.com/modules/module12-analyze.html"/>
    <id>http://blog.url.com/modules/module12-analyze.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-11T23:38:54-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;// Code we need to get them to
from dpla.api import DPLA
import json
from collections import Counter
from nltk.corpus import stopwords&lt;/p&gt;

&lt;p&gt;description_words = []
stop = stopwords.words('english')&lt;/p&gt;

&lt;p&gt;with open("cooking_results.txt") as json_file:
	json_data = json.load(json_file)&lt;/p&gt;

&lt;p&gt;print json.dumps(json_data[1], sort_keys=True, indent=4, separators=(',', ': '))&lt;/p&gt;

&lt;p&gt;def get_words():
	for each in json_data:
		try:
			description = each['sourceResource']['description']
			words = description.split()
			for each in words:
				if each.lower() not in stop:
					if not each.isdigit():
						description_words.append(each.lower())&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	except:
		print "no description"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;get_words()&lt;/p&gt;

</content>
  </entry>
  <entry>
    <title>Gathering a Subset of the Data</title>
    <link rel="alternate" href="http://blog.url.com/modules/module11-subset.html"/>
    <id>http://blog.url.com/modules/module11-subset.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-12T00:11:19-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;In this module, we will learn how to collect and store the description data from each item in our "json_data" variable. To do this, we will first identify the location of the description with the data structure and then loop through each item, saving each of the words in the description into a new list.&lt;/p&gt;

&lt;h3 id="identifying-our-target-fields"&gt;Identifying Our Target Fields&lt;/h3&gt;

&lt;p&gt;Remember back to JSON and how it organizes data using key:value pairs? One of the most powerful features of JSON is that we are able to nest features and create lists within key:value pairs. This is useful for creating complex data structures. It also means that we have work within the hierarchy of key:value pairs to isolate particular values.&lt;/p&gt;

&lt;p&gt;In order to better see that hierarchy, let's &lt;strong&gt;Pretty Print&lt;/strong&gt; the JSON results, or print with the indentations and hierarchies visually displayed. &lt;/p&gt;

&lt;p&gt;Open "my_second_script.py" and &lt;strong&gt;comment out&lt;/strong&gt; "print jason_data[0]" by putting # at the beginning of the line. When your computer executes the file, it will skip all lines that start with a pound sign. This allows you to leave comments for yourself or to test new ways of doing things without loosing your work.&lt;/p&gt;

&lt;p&gt;At the bottom of your script, add the line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print json.dumps(json_data[0], sort_keys=True, indent=4, separators=(',', ': '))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Save and run in Terminal. &lt;/p&gt;

&lt;p&gt;Work with your table to map out what this command did.&lt;/p&gt;

&lt;p&gt;We now need to find the "description" field within the json object. You can either read through all of the lines of code or you can search within Terminal by pressing "command F". &lt;/p&gt;

&lt;p&gt;Looking at the "description" field, work with your table to identify the field name it is nested under. &lt;/p&gt;

&lt;p&gt;The syntax for calling items within a data structure uses brackets to designate the key names or the position in the list of the item we want to interact with. We already use this syntax when we call the first item in the data by using &lt;span class="command"&gt;json_data[0]&lt;/span&gt;. This form means we want the first item in the json_data object. &lt;/p&gt;

&lt;p&gt;If we want the value associated with the "description" key, we use a similar format. &lt;/p&gt;

&lt;p&gt;To print only the description for the first item in our list, add the following to the bottom of your "my_second_script.py" file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print json_data[0]['sourceResource']['description']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Work with your table to print only the titles. What about only the subject headings?&lt;/p&gt;

&lt;h3 id="saving-the-descriptions"&gt;Saving the Descriptions&lt;/h3&gt;

&lt;p&gt;One way to look at the descriptions is to consider them as a collection, or list, of words. If we take all of the collections as a whole, we can ask if there are any noticable patterns in the words being used to describe these items related to cooking.&lt;/p&gt;

&lt;p&gt;One common way of dealing with text computationally is to translate the text into a "bag of words". In a bag of words approach, the order does not matter. What we are looking at instead is the collection of words and their frequencies.&lt;/p&gt;

&lt;p&gt;To create a "bag of words" from the descriptions we need to 1) create a list to store the words and 2) write a loop that takes every description and adds the words to the list.&lt;/p&gt;

&lt;p&gt;See if you can use the information in module 7 (functions and loops) to create an empty list.&lt;/p&gt;

&lt;p&gt;Currently our "my_second_script.py" file should look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import json
from collections import Counter
import nltk
from nltk.corpus import stopwords

with open("search_results.json") as json_file:
  json_data = json.load(json_file)
	
#print json_data[0]
#print json.dumps(json_data[0], sort_keys=True, indent=4, separators=(',', ': '))

print json_data[0]['sourceResource']['description']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I will use "description_words" as the variable for my empty list of stopwords. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;description_words = []
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, we will create a new function called "get_words"&lt;/p&gt;

&lt;p&gt;Declare the function by adding:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_words():
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, tab in once and add a for-loop to move through each item in the json_data list:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_words():
  for each in json_data:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, let's set up a variable to grab the descriptions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_words():
  for each in json_data:
    descriptions = each['sourceResource']['description']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, description holds the full sentence as a single object and we want to get the individual words. We can use a built in function called "split" that divides the sentence into an array of individual objects, splitting on the spaces and punctuation marks.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_words():
  for each in json_data:
    descriptions = each['sourceResource']['description']
    for line in descriptions:
      words = line.split()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To see what just happened, let's add a print statement and call the function:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_words():
  for each in json_data:
    descriptions = each['sourceResource']['description']
    for line in descriptions:
      words = line.split()
      print words

get_words()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your file should now look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import json
from collections import Counter
import nltk
from nltk.corpus import stopwords

with open("search_results.json") as json_file:
  json_data = json.load(json_file)
	
#print json_data[1]
#print json.dumps(json_data[0], sort_keys=True, indent=4, separators=(',', ': '))

print json_data[0]['sourceResource']['description']

description_words = []

def get_words():
  for each in json_data:
    descriptions = each['sourceResource']['description']
    for line in descriptions:
      words = line.split()
      print words

get_words()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Save the file and run it in the terminal.&lt;/p&gt;

&lt;p&gt;You might first notice that this script threw an error, saying:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;KeyError: 'description'
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One of the most important things in learning to work with code is learning to decipher error messages. If you read a little more in your terminal window, you'll see that the full message is something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;jeriwieringa$ python my_second_script.py
[u'This book is published to give greater publicity to the exceptional qualities of Crisco."--Introd.']
[u'This', u'book', u'is', u'published', u'to', u'give', u'greater', u'publicity', u'to', u'the', u'exceptional', u'qualities', u'of', u'Crisco."--Introd.']
Traceback (most recent call last):
  	File "my_second_script.py", line 21, in &amp;lt;module&amp;gt;
	get_words()
  	File "my_second_script.py", line 16, in get_words
	descriptions = each['sourceResource']['description']
KeyError: 'description'
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First, we got a print out of the description sentence and then the words of that description as a list. This is good!&lt;/p&gt;

&lt;p&gt;Then we got a traceback saying in our "get_words()" function there was an error on line 16 where we told it to save the value associated with the "description" key to the variable "descriptions". &lt;/p&gt;

&lt;p&gt;Let's see what is going. Comment out the call to "get_words" function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# get_words()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let's print the second object in the json_data list. Uncomment our print statement at the beginning of the file that pretty-prints the json. Change the 0 to 1, the save and run the file.&lt;/p&gt;

&lt;p&gt;Search for 'description' under 'sourceResource'. If you can't find it, it's because this item appears to be missing "description" information. Because the computer can't find the description, it returns an error and stops.&lt;/p&gt;

&lt;p&gt;Getting around this problem requires what is called "handling exceptions". We had expected a particular pattern in our data (that there was "description" keys nested under "sourceResource" keys) but we've encountered an exception to that general pattern. &lt;/p&gt;

&lt;p&gt;To tell the computer to keep moving if it encounters an item it cannot parse because of a KeyError, we will adjust our get_words() function as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_words():
  for each in json_data:
    try:
      descriptions = each['sourceResource']['description']
      for line in descriptions:
      words = line.split()
        print words
    except KeyError:
      print "Description Missing"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Un-comment "get_words()", save, and run the file.&lt;/p&gt;

&lt;p&gt;Our script should no longer error.&lt;/p&gt;

&lt;p&gt;But, it seems that sometime we are getting a list of letters, and sometimes a list of words. So one more adjustment is in order. We need to perform a check, where if the value of descriptions is a string, the function does one thing, and if it is not a string, it does something else. Our current code works well on the lists, so we will keep that for not strings.&lt;/p&gt;

&lt;p&gt;To check if the value in "descriptions" in a string, we can add the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_words():
  for each in json_data:
    try:
    descriptions = each['sourceResource']['description']
    if isinstance(descriptions, basestring):
      words = descriptions.split()
    else:
      for line in descriptions:
        words = line.split()
        print words
  except KeyError:
    print "Description Missing"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looking through the information printing to our terminal window, it looks like we have correctly split out all of the words.&lt;/p&gt;

&lt;h3 id="adding-the-words-to-our-bag-of-words"&gt;Adding the words to our "bag of words"&lt;/h3&gt;

&lt;p&gt;The final step in creating our subset of data is to add the words into our "description_words" list.&lt;/p&gt;

&lt;p&gt;To do this, we will need to loop through the "words" list and add each word to the "description_words" list. This means another for-loop within the "try" second of our function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_words():
for each in json_data:
  try:
    descriptions = each['sourceResource']['description']
    if isinstance(descriptions, basestring):
      words = descriptions.split()
    else:
      for line in descriptions:
        words = line.split()
    print words

    for word in words:
      description_words.append(word)

  except KeyError:
    print "Description Missing"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now to check that everything worked ok, let's run the function and print out the 1000 word in our "descriptions_words"&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import json
from collections import Counter
import nltk
from nltk.corpus import stopwords

with open("search_results.json") as json_file:
json_data = json.load(json_file)
	
#print json_data[1]
#print json.dumps(json_data[0], sort_keys=True, indent=4, separators=(',', ': '))

#print json_data[0]['sourceResource']['description']

description_words = []

def get_words():
for each in json_data:
  try:
    descriptions = each['sourceResource']['description']
    if isinstance(descriptions, basestring):
      words = descriptions.split()
    else:
      for line in descriptions:
        words = line.split()
    print words

    for word in words:
      description_words.append(word)

  except KeyError:
    print "Description Missing"
  
get_words()
print description_words[999]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bonus Challenges: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Can you modify the function to also add the words of the title to our bag of words?&lt;/li&gt;
  &lt;li&gt;Can you also add the subject headings?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="what-we-learned"&gt;What We Learned&lt;/h3&gt;

&lt;p&gt;In this module, we learned:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to pretty-print json with Python&lt;/li&gt;
  &lt;li&gt;to identify the nested key:value pairs we want to analyze&lt;/li&gt;
  &lt;li&gt;to split a list &lt;/li&gt;
  &lt;li&gt;to trouble shoot from an error report&lt;/li&gt;
  &lt;li&gt;to handle exceptions&lt;/li&gt;
  &lt;li&gt;to check type and use an "if/else" statement&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry>
    <title>Looping through the Pages</title>
    <link rel="alternate" href="http://blog.url.com/modules/module08-whileloop.html"/>
    <id>http://blog.url.com/modules/module08-whileloop.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-11T16:54:00-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;In this module, we will add another loop to our "pull records" function that allows us to move through more than one page of search results.&lt;/p&gt;

&lt;h3 id="introducing-the-while-loop"&gt;Introducing the While Loop&lt;/h3&gt;

&lt;p&gt;The "for loop" allows us to do something to each item in a list. The "while loop" is a powerful tool that tells the computer to continue doing something as long as some criteria is true. We can use the while loop and a "counter" to work through all of the pages of search results.&lt;/p&gt;

&lt;p&gt;To use a while loop, let's look again at our "pull records" function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def pull_records(pages, end, size):
	paged_search = dpla.search(q='cooking', page_size=size, page=pages)
	save_each(paged_search)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remember, "pages" stands for the first page and "end" stands for the last page of search results we want. We want this function to run for every page of search results. In other words, if the page number is less than or equal to the total number of pages available, we want to get the search results from that page. Once we hit the end, we want to stop.&lt;/p&gt;

&lt;p&gt;To write this logic in code, we will add:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;while(pages &amp;lt;= end):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;so that our function now looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def pull_records(pages, end, size):
	while(pages &amp;lt;= end):
		paged_search = dpla.search(q='cooking', page_size=size, page=pages)
		save_each(paged_search)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="adding-a-counter"&gt;Adding a Counter&lt;/h3&gt;

&lt;p&gt;Can you see the problem with our current function? As it currently stands, "pages" is always less than "end" because it never increases. This means we would get stuck in an "infinite loop" if we tried to run the code right now.&lt;/p&gt;

&lt;p&gt;To avoid the infinite loop, we need to increase the value of "pages" each time we work through the loop. We can do this by overwriting the value of "pages" to be "pages + 1".&lt;/p&gt;

&lt;p&gt;After &lt;span class="command"&gt;save_each(paged_search)&lt;/span&gt; add:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pages = pages + 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let's also add a print command to check that things are working as we expect. Above &lt;span class="command"&gt;pages = pages + 1&lt;/span&gt; add:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print "finished page " + str(pages)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our file should now look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from dpla.api import DPLA

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking')
# print result.items[1]

all_records = []

def pull_records(pages, end, size):
	while(pages &amp;lt;= end):
		paged_search = dpla.search(q='cooking', page_size=size, page=pages)
		save_each(paged_search)
		print "finished page " + str(pages)
		pages = pages + 1

def save_each(n):
	for each in n.items:
		all_records.append(each)

pull_records(2, 3, 50)

print all_records[40]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let's test our function on a subset of the pages. Change &lt;span class="command"&gt;pull_records(2, 3, 50)&lt;/span&gt; to &lt;span class="command"&gt;pull_records(2, 5, 50)&lt;/span&gt; and change &lt;span class="command"&gt;print all_records[40]&lt;/span&gt; to &lt;span class="command"&gt;print all_records[150]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Save and run in Terminal.&lt;/p&gt;

&lt;h3 id="what-we-learned"&gt;What We Learned:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;To use a while loop and counter&lt;/li&gt;
  &lt;li&gt;To test on a subset of the data&lt;/li&gt;
  &lt;li&gt;To use "print" to check our functions along the way&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry>
    <title>Functions and Loops</title>
    <link rel="alternate" href="http://blog.url.com/modules/module07-functionsandloops.html"/>
    <id>http://blog.url.com/modules/module07-functionsandloops.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-11T16:17:55-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;We now have a file that looks as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from dpla.api import DPLA

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking')
# print result.items[1]

all_records = []
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We will now add a function that handles the query for any given page number.&lt;/p&gt;

&lt;h3 id="creating-a-pull-records-function"&gt;Creating a "Pull Records" Function&lt;/h3&gt;

&lt;p&gt;To write a function, we set of the function with the word "def" and then indent all of the commands that are part of the function.&lt;/p&gt;

&lt;p&gt;In your "my_first_script.py" file, add the line&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def pull_records(pages, end, size):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You have declared a pull_records function, told the computer that this function will involve three variables (pages, end, and size) and are now ready to add the steps involving in getting the search records. These three variables are arbitrary (you could name them "snap", "crackle", and "pop") but will stand for the first page, the last page, and the number of items per page.&lt;/p&gt;

&lt;p&gt;Tab in one space on the next line and type:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;paged_search = dpla.search(q='cooking', page_size=size, page=pages)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your file should now look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from dpla.api import DPLA

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking')
# print result.items[1]

all_records = []

def pull_records(pages, end, size):
	paged_search = dpla.search(q='cooking', page_size=size, page=pages)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is important to note that Python is white-space aware - when writing functions in Python, we use white space to designate what is in a function or within a loop and what is outside of it.&lt;/p&gt;

&lt;p&gt;Let's add a print statement and test out the first stage of this function. At the same tab as "paged_search…", add:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print paged_search.items[2]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now to run the function, we will call the function name and give it values. On a new line and outside of the function, add the line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pull_records(2, 3, 50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Save the file and go to terminal to run it.&lt;/p&gt;

&lt;h3 id="saving-items-to-all-records"&gt;Saving Items to "All Records"&lt;/h3&gt;

&lt;p&gt;You have written and executed your first function! Well done!&lt;/p&gt;

&lt;p&gt;Now we need to add another function to store those results to the empty "all records" array we set up in the last module. While this is not necessary when you only have one page of results, it becomes necessary when you are trying to save from multiple pages.&lt;/p&gt;

&lt;p&gt;To set up our new "Save Each" function, we will define a new function:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def save_each(n):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The 'n' here is again arbitrary. We are telling the function that there is one variable that we will be passing in and to take that variable and plug it in for 'n' throughout the function.&lt;/p&gt;

&lt;p&gt;We now need to add our first loop. With how we currently have framed our request, there are 50 items in our paged_search item. We want to save each of those items separately to the "all_records" list. This means the computer needs to move through each individual item, take the item and add it to "all_records". &lt;/p&gt;

&lt;p&gt;Tabbing in one space on the next line under &lt;span class="command"&gt;def save_each(n):&lt;/span&gt;s add:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for each in n.items:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is called a "for loop". It tells the computer to iterate through each item in the list 'n'. We use n.items because this is the syntax from the DPyLA library. &lt;/p&gt;

&lt;p&gt;Now we tab in one more space and tell the computer what we want done to each item. To add the item to the "all_records" array, we use the "append" command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;all_records.append(each)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The "save each" function should now look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def save_each(n):
	for each in n.items:
		all_records.append(each)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can use this function in our "pull records" function. Currently, our "pull records" looks as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def pull_records (pages, end, size):
	paged_search = dpla.search(q='cooking', page_size=size, page=pages)
	print paged_search.items[2]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let's delete the "print paged_search.item[2]" line, because that was just there to check that the first bit worked, and add a call to the "save_each" function, passing in our search results. Where the "print" command used to be, add:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;save_each(paged_search)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our file should now look like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from dpla.api import DPLA

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking')
# print result.items[1]

all_records = []

def pull_records(pages, end, size):
	paged_search = dpla.search(q='cooking', page_size=size, page=pages)
	save_each(paged_search)

def save_each(n):
	for each in n.items:
		all_records.append(each)

pull_records(2, 3, 50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To test this, let's now add a print statement to the end of the file, after the pull_records function has been run, to make sure that the items are going into the "all_records" variable.&lt;/p&gt;

&lt;p&gt;Add:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print all_records[30]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Save and run your script.&lt;/p&gt;

&lt;p&gt;We have made great progress! We now have two functions to handle making the query and saving the results, but we are still only working with one "page" of search results at a time. In the next module, we will add yet another kind of loop in order to move through the different pages.&lt;/p&gt;

&lt;h3 id="what-we-learned"&gt;What We Learned&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;To create and call functions&lt;/li&gt;
  &lt;li&gt;To pass variables into functions&lt;/li&gt;
  &lt;li&gt;To create a "for loop"&lt;/li&gt;
  &lt;li&gt;To "append" items into a list&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry>
    <title>Moving to Phase Two</title>
    <link rel="alternate" href="http://blog.url.com/modules/module06-phasetwo.html"/>
    <id>http://blog.url.com/modules/module06-phasetwo.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-11T19:11:19-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;We are at the half-way point, so it is time stop briefly and think through what we have already learned. So far, we have learned to talk to your computer using the terminal. We have interacted with Python, a programming language and used Python to execute a few commands. We have also learned how to use Pip to add additional libraries to Python, and thought about using libraries like lego blocks or cake mix to create new programs. &lt;/p&gt;

&lt;p&gt;We also learned about data and APIs. We looked at JSON as a way of structuring data and thought about what it means to represent things in this format. Then, we looked at the DPLA api and learned how to leverage libraries like DPyLA to use those APIs in our code. Finally, we saved our code in a python file that we learned how to execute in the terminal.&lt;/p&gt;

&lt;p&gt;Well Done!&lt;/p&gt;

&lt;p&gt;So far you have been writing code that does one thing: it get search results or prints a particular item. The power of code, however, is being able to do the same thing to a series of items and it is thinking in terms of iterating through a series that is at the core of computational thinking. To do this, we will learn two very powerful programming concepts: functions and loops.&lt;/p&gt;

&lt;h3 id="asking-questions-of-our-data"&gt;Asking Questions of Our Data&lt;/h3&gt;

&lt;p&gt;We have been able to do a lot with filtering the data by subject headings, by geographic space, and by contributor. But what if we want to ask questions about how the materials are described across all 10,000+ items associated with "cooking"? Say we are interested in how those descriptions of items related to cooking are gendered. How would we investigate patterns across the entirety of the DPLA's holdings related to "cooking"?&lt;/p&gt;

&lt;p&gt;There are many ways one could go about investigating the descriptions. Work with your table to brain-storm a couple of approaches.&lt;/p&gt;

&lt;h3 id="adding-parameters-to-the-query"&gt;Adding Parameters to the Query&lt;/h3&gt;

&lt;p&gt;To start, we need to restructure our query so that we can control the number of items and the "page" we get the data from. Remember that the API by default gives us 10 items at a time. We can pass a variable to get up to 500 items at a time, but there were 10,909 items associated with "cooking".&lt;/p&gt;

&lt;p&gt;Open your "my_first_script.py" file. Looking at the line that says &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;result = dpla.search('cooking')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;we can change the number of items we get back by adding an additional parameter to what we pass to dpla.search. Looking at the documentation, we learn that the syntax for setting the number of items is &lt;span class="command"&gt;page_size=&lt;/span&gt; and the number of items we want. To get 50 items rather than 10, change that line to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;result = dpla.search('cooking', page_size=50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To check that this worked, let's add a line telling the computer to print out the 40th item:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print result.items[39]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remember, counting within a list begins at 0.&lt;/p&gt;

&lt;p&gt;Use the &lt;a href="https://github.com/bibliotechy/DPyLA"&gt;documentation&lt;/a&gt; and your table to add another parameter to get the information from page 3.&lt;/p&gt;

&lt;h3 id="setting-up-a-variable"&gt;Setting Up a Variable&lt;/h3&gt;

&lt;p&gt;To get all 10,000+ items associated with cooking, we need to do two things: we need to get the items all of the pages and we need a place to store them, so that as we get new items, our collections grows.&lt;/p&gt;

&lt;p&gt;Let's tackle the second problem first. Remember back to variables? Variables are names we used to hold values. We can also use variables to hold lists. For example, I could create a list "fruit" that has the values "apple, orange, banana" by doing the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fruit = ["apple", "orange", "banana"]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;now if I ask for the second item in fruit&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fruit[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I will get back "orange".&lt;/p&gt;

&lt;p&gt;We are going to use a similar structure to save all of the items we get back from the DPLA.&lt;/p&gt;

&lt;p&gt;Go back to "my_first_script.py". Comment out the line &lt;span class="command"&gt;result = dpla.search('cooking', page_size=50)&lt;/span&gt; by placing a # sign at the front of the line. This tells the computer to skip this line. Also comment out the line you wrote to print out one of the items.&lt;/p&gt;

&lt;p&gt;Your file should look something like this: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from dpla.api import DPLA

dpla = DPLA('YourKeyHere')

# result = dpla.search('cooking')
# print result.items[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, let's create a new variable, "all_records" and set it equal to an empty list.&lt;/p&gt;

&lt;p&gt;To do this, add a new line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;all_records = []
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This tells the computer that we have a variable, "all_records", that this variable will hold a list, and that we currently have no items in that list.&lt;/p&gt;

&lt;p&gt;Now that we have a place to store our values, we now have to tell the computer to get the search results from each page and save those results to the "all_records" list.&lt;/p&gt;

&lt;h3 id="what-we-learned"&gt;What We Learned&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;To add additional parameters to our API call&lt;/li&gt;
  &lt;li&gt;To create an empty list&lt;/li&gt;
  &lt;li&gt;To comment-out code that we don't want to run, but want to keep&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
</feed>
