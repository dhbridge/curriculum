<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog Name</title>
  <subtitle>Blog subtitle</subtitle>
  <id>http://blog.url.com/modules</id>
  <link href="http://blog.url.com/modules"/>
  <link href="http://blog.url.com/feed.xml" rel="self"/>
  <updated>2014-10-06T20:00:00-04:00</updated>
  <author>
    <name>Blog Author</name>
  </author>
  <entry>
    <title>Overview for Coaches</title>
    <link rel="alternate" href="http://blog.url.com/modules/coaches-guide.html"/>
    <id>http://blog.url.com/modules/coaches-guide.html</id>
    <published>2014-10-06T20:00:00-04:00</published>
    <updated>2014-10-26T19:52:57-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;Welcome to being a coach for a DH Bridge workshop! This document will orient you to the goals and objectives for the day (and beyond), how the tutorials have been scaffolded, and the places where your expertise will be needed to guide participants. &lt;/p&gt;

&lt;h3 id="goals-and-objectives"&gt;Goals and Objectives&lt;/h3&gt;

&lt;p&gt;Coaches will: &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Be mindful of the obstacles that make it difficult for persons from underrepresented groups to learn to code, and be respectful of particpants' efforts to learn.&lt;/li&gt;
  &lt;li&gt;Foster collegial interaction between participants in their group, and encourage participants to collaborate and help each other when possible. &lt;/li&gt;
  &lt;li&gt;Facilitate participants' forays into computational thinking by highlighting the relationships between data, content, and questions.&lt;/li&gt;
  &lt;li&gt;Encourage participants to avoid self-deprecating/apologetic language (I'm not sure if I'm smart enough, I'm not very good with technology, etc.). &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="tips-for-the-day"&gt;Tips for the Day&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Not all questions have solutions, errors will happen, and that's ok. Talk through participants' results, and move them toward forming their own questions to troubleshoot.&lt;/li&gt;
  &lt;li&gt;If a group is progressing quickly through the tutorials, have them explain back what the different lines of code are doing and/or complete the Bonus Challenges on the relevant tutorials. &lt;/li&gt;
  &lt;li&gt;There shouldn't be any copying/pasting of the code.&lt;/li&gt;
  &lt;li&gt;Only 1 folder should be used for the entire workshop.&lt;/li&gt;
  &lt;li&gt;Ask before taking over a participant's machine to demonstrate or fix a problem, and only do so if absolutely necessary. &lt;/li&gt;
  &lt;li&gt;There are "Learning Checks" for each module below. Each "Learning Check" is a question or activity to help make sure that participants aren't missing any of the concepts and terms introduced in each module.&lt;/li&gt;
  &lt;li&gt;To make things easy on everyone, the following terminology will be used consistently throughout the day:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Terminal and Powershell = Terminal
Directories and Folders = Folders &lt;/p&gt;

&lt;p&gt;For Mac/Windows term translation: &lt;a href="http://www.dummies.com/how-to/content/comparing-common-windows-terms-with-mac-terms.html"&gt;http://www.dummies.com/how-to/content/comparing-common-windows-terms-with-mac-terms.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="draft-full-day-schedule"&gt;Draft Full Day Schedule&lt;/h3&gt;

&lt;p&gt;Note: some of the timeblocks may shift based on the progress of the participants.&lt;/p&gt;

&lt;p&gt;9:30-10:20a&lt;/p&gt;

&lt;p&gt;Welcome and Setting Up the Learning Environment: goals and objectives for the day, introductions within small groups.&lt;/p&gt;

&lt;p&gt;Coaches' Project Demonstrations: current projects and problems&lt;/p&gt;

&lt;p&gt;10 Minute Break&lt;/p&gt;

&lt;p&gt;10:30-Noon: Modules 1-5&lt;/p&gt;

&lt;p&gt;LUNCH&lt;/p&gt;

&lt;p&gt;1:00-2:30p: Modules 6 - 8&lt;/p&gt;

&lt;p&gt;10 Minute Break&lt;/p&gt;

&lt;p&gt;2:40-4:00p: Modules 9 - 11&lt;/p&gt;

&lt;p&gt;4:00-5:00p: Modules 12 - 13&lt;/p&gt;

&lt;p&gt;5:00-5:30: Wrapup (recap the day and tips for continued learning)&lt;/p&gt;

&lt;p&gt;5:30: Decompressing and socializing&lt;/p&gt;

&lt;h3 id="installation"&gt;Installation&lt;/h3&gt;

&lt;p&gt;Check to make sure that participants have the following installed and ready to go:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Python 2.7&lt;/li&gt;
  &lt;li&gt;Pip&lt;/li&gt;
  &lt;li&gt;Text Editor: work with participants to set TextWrangler as the default text editor for Mac users. It's not an issue for Windows users because the commands specify Notepad++ each time. &lt;/li&gt;
  &lt;li&gt;Chrome browser&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If possible, please have participants pin the text editor and Chrome to their Dock (Mac)/Taskbar (Windows), or at least have them easily accessible. &lt;/p&gt;

&lt;h3 id="module-1-to-be-done-with-full-group"&gt;Module 1 (to be done with full group)&lt;/h3&gt;

&lt;p&gt;Learning Checks:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;After your group members have all created their folder "dhb_awesome" have them find the folder through Finder/My Computer. Have them compare the directory path with what they did in Terminal to ensure they can see that they are creating files and folders on their local machine.   &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="module-2"&gt;Module 2&lt;/h3&gt;

&lt;p&gt;Start with the DPLA interface in the browser and search for "cooking". Have group read what's going on in the URL. Filter number of items displayed. How did the URL change? What's the syntax?  &lt;/p&gt;

&lt;p&gt;Learning Checks:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Have them talk through the API request URL to reinforce understanding of the structure of the request.&lt;/li&gt;
  &lt;li&gt;Review how JSON stores data items as objects and how it displays those objects.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="module-3"&gt;Module 3&lt;/h3&gt;

&lt;p&gt;Learning Checks: &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Make sure participants are clear on difference between Python Interactive Shell and Terminal.&lt;/li&gt;
  &lt;li&gt;Terminology check: string, variable, array/list&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="module-4"&gt;Module 4&lt;/h3&gt;

&lt;p&gt;Learning Checks:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Constructing additional queries: highlight the questions that would motivate the choice of different commands and filtering of results.&lt;/li&gt;
  &lt;li&gt;See if there are any general questions about APIs and the documentation used in the module. &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="module-5"&gt;Module 5&lt;/h3&gt;

&lt;p&gt;Learning Checks: programming languages and libraries&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Mapping Exercise #1: have participants diagram the following, similar to the API exercise from earlier in the day:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;-High-level programming languages (like Python) enable you to write commands for your computer in something that approximates English. Those commands are then translated down to machine language, executed by the hardware, and the results are translated back to generate the desired output. Your computer is constantly processing commands from the applications on your machine in multiple programming languages. Just like those applications, you can use the terminal interface to send commands to your computer.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Discuss everyone's diagrams and make sure the concepts are clear.&lt;/li&gt;
  &lt;li&gt;Mapping Exercise #2: have participants diagram the following, similar to the API exercise from earlier in the day:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;-A Python module or library is a bundle of code, including variables and functions (defined processes), that does a particular task. Many Python modules already exist out in the world, ready to be used, and new ones are developed by programmers all the time. Python scripts, which combine these modules with additional python commands, give the computer new, and more complicated, tasks that can be completed.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Discuss everyone's diagrams and make sure the concepts are clear.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id="module-6"&gt;Module 6&lt;/h3&gt;

&lt;p&gt;Before your group jumps into the code-heavy part of the module, start off with the quick review of how script files should be organized. There will also be a handout for participants to reference as they continue through the modules. Participants may be tempted to gloss over this part, but make sure they take the time to get the format down. 
1. libraries to import
2. variables to be used throughout the script
3. functions
4. calls/commands to execute the functions&lt;/p&gt;

&lt;p&gt;Terminology related to functions: from now on the tutorials will use new phrases to describe how the functions work in relation to the data. These phrases are part of programming vernacular, and so they're not jarring to participants, here are some basic definitions:
1. call: to execute 
2. declare: set up a new function
3. pass: to run data through the function/loop&lt;/p&gt;

&lt;p&gt;Learning Checks:
1. Have a quick discussion about the merits of commenting out versus deleting lines
2. Verify that participants understand setting variables and how they can hold lists (an empty list so far.
2. Group challenge, "for loop" exercise: check that the participants have a solid grasp on the function and purpose of a "for loop"&lt;/p&gt;

&lt;h3 id="module-7"&gt;Module 7&lt;/h3&gt;

&lt;p&gt;Learning Checks: 
1. Review and explain in a group discussion: how functions can be combined to solve problems, with the example of the two functions written so far and how they work together.
2. Review what "append" does.
3. Group challenge: talk through the functionality and uses for a "for loop"&lt;/p&gt;

&lt;h3 id="module-8"&gt;Module 8&lt;/h3&gt;

&lt;p&gt;Learning Checks: 
1. Group challenge: along with talking through how a "while loop" works, also review why the "while loop" is added into the function where it is. 
2. Cover why an "infinite loop" is bad.&lt;/p&gt;

&lt;h3 id="module-9"&gt;Module 9&lt;/h3&gt;

&lt;p&gt;Learning Checks:
1. &lt;/p&gt;

&lt;h3 id="module-10"&gt;Module 10&lt;/h3&gt;

&lt;p&gt;Learning Checks:
1. &lt;/p&gt;

&lt;h3 id="module-11"&gt;Module 11&lt;/h3&gt;

&lt;p&gt;Learning Checks: &lt;/p&gt;

&lt;h3 id="module-12"&gt;Module 12&lt;/h3&gt;

&lt;p&gt;Learning Checks:&lt;/p&gt;

&lt;h3 id="module-13"&gt;Module 13&lt;/h3&gt;

&lt;p&gt;Learning Checks:
1. Have participants pull out their diagrams of Terminal, API, and programming languages and make any necessary revisions based on what they've learned throughout the day. &lt;/p&gt;

</content>
  </entry>
  <entry>
    <title>Functions and Loops</title>
    <link rel="alternate" href="http://blog.url.com/modules/module07.html"/>
    <id>http://blog.url.com/modules/module07.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-26T11:30:50-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;In this module, we will learn&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;to create and call functions&lt;/li&gt;
  &lt;li&gt;to create a "for loop"&lt;/li&gt;
  &lt;li&gt;to "append" or add items into a list&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We are now ready to start writing a function to gather all of the information we want from the DPLA.&lt;/p&gt;

&lt;p&gt;We now have a file that looks as follows:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;from dpla.api import DPLA

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking', fields=['sourceResource'], page_size = 50)
# print result.items[1]

all_records = []
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We will now add a function that handles the query for any given page number.&lt;/p&gt;

&lt;h3 id="creating-a-pull-records-function"&gt;1. Creating a "Pull Records" Function&lt;/h3&gt;

&lt;p&gt;Functions are little packets of code that do particular tasks. They involve variables, and processes, and the take what is given to them, and spit out a result. &lt;/p&gt;

&lt;p&gt;To write a function, we start with the word "def", then give our function a name, and finally end with '():' Inside the parenthese, we can indicate how many pieces of information are going into the function.&lt;/p&gt;

&lt;p&gt;In your "my_first_script.py" file, add the line&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def pull_records(pages, end, size):
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;In this line, you have declared a 'pull_records' function, and told the computer that this function will involve three variables (pages, end, and size).These three variables are arbitrary (you could name them "snap", "crackle", and "pop") but will stand for the first page, the last page, and the number of items per page. &lt;/p&gt;

&lt;p&gt;We are now ready to add the steps involving in getting the search records. &lt;/p&gt;

&lt;p&gt;Tab in once on the next line and type:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def pull_records(pages, end, size):
	paged_search = dpla.search('cooking', fields=['sourceResource'], page_size=size, page=pages)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Your file should now look like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;from dpla.api import DPLA

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking', fields=['sourceResource'], page_size = 50)
# print result.items[1]

all_records = []

def pull_records(pages, end, size):
	paged_search = dpla.search('cooking', fields=['sourceResource'], page_size=size, page=pages)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;It is important to note that Python is white-space aware - when writing functions in Python, we use white space to designate what is in a function or within a loop and what is outside of it.&lt;/p&gt;

&lt;p&gt;Let's add a print statement to our function and test out the first stage of this function. Add the following print statement after 'paged_searchâ€¦':&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def pull_records(pages, end, size):
	paged_search = dpla.search('cooking', fields=['sourceResource'], page_size = size, page = pages)
	print paged_search.items[2]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now to run the function, we will call the function name and give it values. On a new line and outside of the function, add the line:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;pull_records(2, 3, 50)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Your file should now look like:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;from dpla.api import DPLA

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking', fields=['sourceResource'], page_size = 50)
# print result.items[1]

all_records = []

def pull_records(pages, end, size):
	paged_search = dpla.search('cooking',fields=['sourceResource'],  page_size=size, page=pages)
	print paged_search.items[2]

pull_records(2, 3, 50)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Save the file and go to terminal to run it. Then come back to the function and work with your table to understand how the function worked.&lt;/p&gt;

&lt;h3 id="using-a-for-loop-to-save-items-to-allrecords"&gt;2. Using a 'for loop' to save items to 'all_records'&lt;/h3&gt;

&lt;p&gt;You have written and executed your first function! Well done!&lt;/p&gt;

&lt;p&gt;Now we need to add another function to store those results to the empty 'all_records' array we set up in the last module. While this is not necessary when you only have one page of results, it becomes necessary when you are trying to save from multiple pages.&lt;/p&gt;

&lt;p&gt;To set up our new "Save Each" function, we will define a new function in our my_first_script.py file. Good practice is to group our functions together toward the top of the file, so put the "save_each" function after we defined "pull_records" but before we call the "pull_records" function:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def save_each(n):
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The 'n' here is again arbitrary. We are telling the function that there is one variable that we will be passing in and to take that variable and plug it in for 'n' throughout the function.&lt;/p&gt;

&lt;p&gt;We now need to add our first loop. With our current search, there are 50 items in our paged_search variable. We want to save each of those items separately to the 'all_records' list. This means the computer needs to move through each individual item, grab the item, and add it to 'all_records'. &lt;/p&gt;

&lt;p&gt;Tabbing in one space on the next line under &lt;span class="command"&gt;def save_each(n):&lt;/span&gt;s add:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;for each in n.items:
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This is called a "for loop". It tells the computer to iterate through each item in the list 'n'. &lt;/p&gt;

&lt;p&gt;Because this is a process inside a process, we need to tab in again. Each time we have a new loop or new function, we tab in all the lines associated with that process. To show that we're done listing steps for a particular process, we tab back out.&lt;/p&gt;

&lt;p&gt;To add the item to the "all_records" array, we use the "append" command:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;all_records.append(each)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;'append' grabs the value of 'each' and adds it to the series we are saving as a list.&lt;/p&gt;

&lt;p&gt;Your 'save_each()' function should now look like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def save_each(n):
	for each in n.items:
		all_records.append(each)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now we can use this function in our "pull records" function. Currently, our "pull records" looks as follows:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def pull_records (pages, end, size):
	paged_search = dpla.search('cooking', fields=['sourceResource'],  page_size=size, page=pages)
	print paged_search.items[2]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Let's comment out the "print paged_search.item[2]" line, because that was just there to check that the first bit worked, and add a call to the "save_each" function, passing in our search results. &lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def pull_records (pages, end, size):
	paged_search = dpla.search('cooking', fields=['sourceResource'],  page_size=size, page=pages)
	# print paged_search.items[2]	
	save_each(paged_search)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Our file should now look like:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;from dpla.api import DPLA

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking', fields=['sourceResource'], page_size = 50)
# print result.items[1]

all_records = []

def pull_records(pages, end, size):
	paged_search = dpla.search('cooking',fields=['sourceResource'],   page_size=size, page=pages)
	# print paged_search.items[2]	
	save_each(paged_search)

def save_each(n):
	for each in n.items:
		all_records.append(each)

pull_records(2, 3, 50)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;To test this, let's now add a print statement to the end of the file, after the pull_records function has been run, to make sure that the items are going into the "all_records" variable.&lt;/p&gt;

&lt;p&gt;After 'pull_records()' add:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;print all_records[30]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Save and run your script.&lt;/p&gt;

&lt;p&gt;We have made great progress! We now have two functions to handle making the query and saving the results, but we are still only working with one "page" of search results at a time. In the next module, we will add yet another kind of loop in order to move through the different pages.&lt;/p&gt;

&lt;h3 id="group-challenge"&gt;Group Challenge&lt;/h3&gt;

&lt;p&gt;Break out the paper and pencils. Work as a group to create a diagram or metaphor for a "for loop". What types of situations would you use a 'for loop' in?  &lt;/p&gt;

&lt;p&gt;&lt;span class="left"&gt;&lt;a href="module06.html"&gt;Previous Module&lt;/a&gt;&lt;/span&gt;
&lt;span class="right"&gt;&lt;a href="module08.html"&gt;Next Module&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Analyzing a Subset of the Data</title>
    <link rel="alternate" href="http://blog.url.com/modules/module12.html"/>
    <id>http://blog.url.com/modules/module12.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-26T10:00:22-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;We now have a bag of words that we can do some analysis on. In this module, we will ask some basic questions about word frequencies, make some adjustments to our collection of words to improve the results, and discuss what additional questions those patterns might raise.&lt;/p&gt;

&lt;h3 id="getting-word-frequencies"&gt;Getting Word Frequencies&lt;/h3&gt;

&lt;p&gt;To get word frequencies, we will use the "Counter" library we loaded earlier. Looking at the &lt;a href="https://docs.python.org/2/library/collections.html#collections.Counter"&gt;documentation for the library&lt;/a&gt;, we see that if we pass "Counter" a list, we can get back information regarding the items in the list, including the most common items.&lt;/p&gt;

&lt;p&gt;Add a new line to the bottom of "my_second_script.py" as follows:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;c = Counter(description_words)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Notice the capitalization here. Because the library has the name of "Counter", we need to keep that "C" uppercase whenever we use the library. &lt;/p&gt;

&lt;p&gt;Now we will use the method "most_common" and let's start with the top 200 words:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;print c.most_common(200)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Comment out the "print words" statements from the last module (so that we can see what is going on), then save and run the file.&lt;/p&gt;

&lt;p&gt;You should see a list of words and frequencies that looks like this: &lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;(u'the', 11873), (u'of', 8435), (u'and', 7689), (u'in', 5553), (u'a', 4542), (u'to', 4375), (u'is', 2150), (u'1', 2090), (u'for', 2080), (u'on', 1897), (u'The', 1808), (u'was', 1632), (u'with', 1590), (u';', 1440), (u'by', 1408), (u':', 1389), (u'photograph', 1324), (u'from', 1191), (u'at', 1179), (u'as', 1140), (u'that', 1136), (u'are', 1035), (u'x', 1023), (u'be', 990), (u'or', 979), (u'2', 877), (u'0', 776), (u'2014', 740), (u'I', 734), (u'were', 714), (u'b&amp;amp;w', 691), (u'cooking', 685), (u'3', 685), (u'in.', 675), (u'4', 674), (u'it', 665), (u'this', 663), (u'which', 632), (u'5', 578), (u'have', 571), (u'.', 543), (u'cm.', 513), (u'an', 501), (u'their', 494), (u'about', 489), (u'This', 488), (u'not', 477), (u'col.', 468), (u'negative,', 460), (u'It', 441), (u'these', 438), (u'12', 429), (u'A', 425), (u'will', 423), (u'35', 415), (u'has', 413), (u'In', 411), (u'mm.', 395), (u'Jun', 391), (u'p.', 386), (u'they', 384), (u'food', 381), (u'had', 379), (u'all', 376), (u'we', 368), (u'he', 367)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;But for the most part, these words are not terribly interesting to us. The prevalence of "the" and "of" doesn't tell us much about how "cooking" is described and are making it hard to a pattern in the nouns and verbs. &lt;/p&gt;

&lt;p&gt;There is a second problem. If you notice, "the" is in the list twice, once as "the" and once as "The". Computers, being ever the literal processors, take the difference in case to indicate a difference in word. This can be very helpful in some circumstances, like finding names. But when just looking for a rough count of words, it creates noise.&lt;/p&gt;

&lt;p&gt;To address these problems, we can remove those function words and transform all the words to lowercase, using the Natural Language ToolKit.&lt;/p&gt;

&lt;h3 id="removing-stopwords"&gt;Removing StopWords&lt;/h3&gt;

&lt;p&gt;Going back to our "get_words" function, one way to remove the stopwords is to check if the word is in a standard list of function words before adding it to the bag.&lt;/p&gt;

&lt;p&gt;The logic here is, if the word is not a stopword, then we want to save it to our "description_words" list.&lt;/p&gt;

&lt;p&gt;To do this, let's create a second function for checking the stopwords.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def remove_stops_and_add(word):
    if word.lower() not in stop:
        description_words.append(word.lower())
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Here we are combining two steps in one. We transform each word as it comes in to the lower case with ".lower()" before we check it against the stop words. Then we transform it again before we append it to our "description_words" list. &lt;/p&gt;

&lt;p&gt;We could also transform it once at the beginning of this function. Work with your table to work out how would you change the function to do that.&lt;/p&gt;

&lt;p&gt;Now, we also need to load up the stopwords from nltk library into a variable "stop". &lt;/p&gt;

&lt;p&gt;On the line after we set up our "description_words" list, add:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;stop = stopwords.words('english')
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Here we are loading up the collection of english stop words from the stopwords library.&lt;/p&gt;

&lt;p&gt;Finally, we need to call this new function inside our "get_words()" function. &lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_words():
    for each in json_data:
        try:
            descriptions = each['sourceResource']['description']
            if isinstance(descriptions, basestring):
                words = descriptions.split()
            else:
                for line in descriptions:
                    words = line.split()
            
            for word in words:
                remove_stops_and_add(word)

        except KeyError:
            print "Description Missing"
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Save and run your script.&lt;/p&gt;

&lt;p&gt;Now our results should look something like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;[(u'1', 2090), (u'photograph', 1520), (u';', 1440), (u':', 1389), (u'x', 1057), (u'2', 877), (u'cooking', 779), (u'0', 776), (u'2014', 740), (u'b&amp;amp;w', 691), (u'3', 685), (u'in.', 675), (u'4', 674), (u'5', 578), (u'.', 543), (u'cm.', 513), (u'food', 471), (u'col.', 468), (u'may', 462), (u'negative,', 460), (u'one', 440), (u'12', 429), (u'35', 415), (u'p.', 408), (u'also', 404), (u'mm.', 396), (u'two', 393), (u'jun', 391), (u'6', 358), (u'would', 347), (u'clark', 345), (u'includes', 332), (u'time', 327), (u'molasses', 325), (u'new', 324), (u'people', 315), (u'20', 306), (u'well', 301), (u'state', 301), (u'early', 288), (u'work', 284), (u'water', 283), (u'university', 282), (u'positive,', 280), (u'home', 276), (u'joe', 275), (u'per', 270), (u'farm', 269), (u'information', 263), (u'school', 251), (u'three', 251), (u'-', 250), (u'first', 243), (u'8', 238), (u'used', 237), (u'7', 235), (u'good', 231), (u'10', 227), (u'large', 217), (u'no.', 216), (u'published', 213), (u'library', 207), (u'9', 206)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This is much better! But now we have some distracting numbers and punctuation marks. So let's get rid of those too.&lt;/p&gt;

&lt;p&gt;Going back to our new "remove_stops_and_add()" function, let's add a few more filters that the words must pass through before we add it to the bag.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def remove_stops_and_add(word):
    if word.lower() not in stop:
        if not word.isdigit():
            description_words.append(word.lower())
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This checks to see if the words is a digit and if it is not, then it allows it to pass. We also had some punctuation marks and abbreviations. To remove these, we can allow only those words that are alphanumeric to pass before we add to "description_words". &lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def remove_stops_and_add(word):
    if word.lower() not in stop:
        if not word.isdigit():
            if word.isalnum():
                description_words.append(word.lower())
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;And well done! We now have a very interesting list of description words and their frequencies across all of the "cooking" items in the DPLA's holdings.&lt;/p&gt;

&lt;h3 id="group-challege"&gt;Group Challege&lt;/h3&gt;

&lt;p&gt;You can also use "stemming" to combine multipe forms of the same word, such as "photograph" and "photographs". Can you use the &lt;a href="http://www.nltk.org/api/nltk.stem.html"&gt;NLTK documentation&lt;/a&gt; to add another filter that stems the words before adding them to "description_words"?&lt;/p&gt;

&lt;h3 id="what-we-learned"&gt;What We Learned&lt;/h3&gt;

&lt;p&gt;In this module, we learned:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to use stopwords and filters to clean up noisy data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span class="left"&gt;&lt;a href="module11.html"&gt;Previous Module&lt;/a&gt;&lt;/span&gt;
&lt;span class="right"&gt;&lt;a href="module13.html"&gt;Next Module&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Analyzing the Data (Part 1)</title>
    <link rel="alternate" href="http://blog.url.com/modules/module11.html"/>
    <id>http://blog.url.com/modules/module11.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-26T19:58:23-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;h3 id="installing-nltk"&gt;Installing NLTK&lt;/h3&gt;

&lt;p&gt;We are interested in the languaged used in the "description" fields across all the "cooking" items in the DPLA database. Fortunately, there is good support within Python for text analysis and one power library we can use is the Natural Language ToolKit (or NLTK).&lt;/p&gt;

&lt;p&gt;To install NLTK, let's go back to our terminal and use pip.&lt;/p&gt;

&lt;p&gt;Run &lt;span class="command"&gt;pip install nltk&lt;/span&gt;. You may need to use &lt;span class="command"&gt;sudo pip install nltk&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;Now, go back to your file and import nltk at the top of the file.&lt;/p&gt;

&lt;p&gt;There are also a number of datasets available for use with nltk. For our purposes, we will only be using the 'stopwords' dataset, but you can browse the list of all the datasets you could download and use at &lt;a href="http://www.nltk.org/nltk_data/"&gt;http://www.nltk.org/nltk_data/&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;To download the stopwords, we are going to go back into the Python Interactive Shell. Run &lt;span class="command"&gt;python&lt;/span&gt;. Your terminal window should now look something like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;Python 2.7.5 (default, Mar  9 2014, 22:15:05)
[GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&amp;gt;&amp;gt;&amp;gt; 
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Type &lt;span class="command"&gt;import nltk&lt;/span&gt; and press enter.&lt;/p&gt;

&lt;p&gt;Next type &lt;span class="command"&gt;nltk.download('stopwords')&lt;/span&gt; and press enter.&lt;/p&gt;

&lt;p&gt;Once you see &lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;True
&amp;gt;&amp;gt;&amp;gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;you have successfully downloaded the stopwords file. You can now exit the Python Interactive Shell using &lt;span class="command"&gt;quit()&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Great!&lt;/p&gt;

&lt;p&gt;Now we need to load these stopwords into our Python file. Switching back to our "my_second_script.py" file, add &lt;span class="command"&gt;from nltk.corpus import stopwords&lt;/span&gt; to the top of the file.&lt;/p&gt;

&lt;p&gt;Your file should now look like:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;import json
from collections import Counter
import nltk
from nltk.corpus import stopwords

with open("search_results.json") as json_file:
    json_data = json.load(json_file)

#print json_data[1]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We are now ready to start working with our data.&lt;/p&gt;

&lt;h3 id="what-we-learned"&gt;What We Learned&lt;/h3&gt;

&lt;p&gt;In this module, we have reviewed and learned:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to create new files using terminal&lt;/li&gt;
  &lt;li&gt;to load json data from a file &lt;/li&gt;
  &lt;li&gt;to download libraries using pip&lt;/li&gt;
  &lt;li&gt;to download datasets within libraries&lt;/li&gt;
  &lt;li&gt;to load libraries into our scripts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this module, we will learn how to collect and store the description data from each item in our "json_data" variable. To do this, we will first identify the location of the description with the data structure and then loop through each item, saving each of the words in the description into a new list.&lt;/p&gt;

&lt;h3 id="identifying-our-target-fields"&gt;Identifying Our Target Fields&lt;/h3&gt;

&lt;p&gt;Remember back to JSON and how it organizes data using key:value pairs? One of the most powerful features of JSON is that we are able to nest features and create lists within key:value pairs. This is useful for creating complex data structures. It also means that we have work within the hierarchy of key:value pairs to isolate particular values.&lt;/p&gt;

&lt;p&gt;In order to better see that hierarchy, let's "Pretty Print" the JSON results, or print with the indentations and hierarchies visually displayed. &lt;/p&gt;

&lt;p&gt;Open "my_second_script.py" and "comment out" "print jason_data[0]" by putting # at the beginning of the line.&lt;/p&gt;

&lt;p&gt;At the bottom of your script, add the line:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;print json.dumps(json_data[1], sort_keys=True, indent=4, separators=(',', ': '))
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Save and run in Terminal. &lt;/p&gt;

&lt;p&gt;Work with your table to map out what this command did.&lt;/p&gt;

&lt;p&gt;We now need to find the "description" field within the json object. You can either read through all of the lines of code or you can search within Terminal by pressing "command F" on a Mac and Windows, click the menu button and go to Edit -&amp;gt; Find. &lt;/p&gt;

&lt;p&gt;Looking at the "description" field, work with your table to identify the key name it is nested under. &lt;/p&gt;

&lt;p&gt;The syntax for calling items within a data structure uses brackets to designate the key names or the position in the list of the item we want to interact with. We already use this syntax when we call the first item in the data by using &lt;span class="command"&gt;json_data[1]&lt;/span&gt;. This form means we want the first item in the json_data object. &lt;/p&gt;

&lt;p&gt;If we want the value associated with the "description" key, we use a similar format. &lt;/p&gt;

&lt;p&gt;To print only the description for the first item in our list, add the following to the bottom of your "my_second_script.py" file:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;print json_data[1]['sourceResource']['description']
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Work with your table to print only the titles. What about only the subject headings?&lt;/p&gt;

&lt;h3 id="saving-the-descriptions"&gt;Saving the Descriptions&lt;/h3&gt;

&lt;p&gt;One way to look at the descriptions is to consider them as a collection, or list, of words. If we take all of the collections as a whole, we can ask if there are any noticable patterns in the words being used to describe these items related to cooking.&lt;/p&gt;

&lt;p&gt;One common way of dealing with text computationally is to translate the text into a "bag of words". In a bag of words approach, the order does not matter. What we are looking at instead is the collection of words and their frequencies.&lt;/p&gt;

&lt;p&gt;To create a "bag of words" from the descriptions we need to 1) create a list to store the words and 2) write a loop that takes every description and adds the words to the list.&lt;/p&gt;

&lt;p&gt;See if you can use the information in module 7 (functions and loops) to create an empty list.&lt;/p&gt;

&lt;p&gt;Currently our "my_second_script.py" file should look like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;import json
from collections import Counter
import nltk
from nltk.corpus import stopwords

with open("search_results.json") as json_file:
   json_data = json.load(json_file)
	
#print json_data[1]
#print json.dumps(json_data[1], sort_keys=True, indent=4, separators=(',', ': '))

print json_data[1]['sourceResource']['description']
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Let's use "description_words" as the variable for our empty list of stopwords. Remember that variables go after we import the libraries and before our functions. &lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;description_words = []
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Next, we will create a new function called "get_words"&lt;/p&gt;

&lt;p&gt;Declare the function by adding:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_words():
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Next, tab in once and add a for-loop to move through each item in the json_data list:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_words():
   for each in json_data:
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Next, let's set up a variable to grab the descriptions:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_words():
    for each in json_data:
        descriptions = each['sourceResource']['description']
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now, description holds the full sentence as a single object and we want to get the individual words. We can use a built in function called "split" that divides the sentence into an array of individual objects, splitting on the spaces and punctuation marks.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_words():
    for each in json_data:
        descriptions = each['sourceResource']['description']
        for line in descriptions:
            words = line.split()
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;To see what just happened, let's add a print statement:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_words():
    for each in json_data:
        descriptions = each['sourceResource']['description']
        for line in descriptions:
            words = line.split()
            print words
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now "call the function" by adding &lt;span class="command"&gt;get_words()&lt;/span&gt; to the end of the file.	&lt;/p&gt;

&lt;p&gt;Your file should now look like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;import json
from collections import Counter
import nltk
from nltk.corpus import stopwords

with open("search_results.json") as json_file:
    json_data = json.load(json_file)

description_words = []	

def get_words():
    for each in json_data:
        descriptions = each['sourceResource']['description']
        for line in descriptions:
            words = line.split()
            print words

#print json_data[1]
#print json.dumps(json_data[1], sort_keys=True, indent=4, separators=(',', ': '))

print json_data[1]['sourceResource']['description']

get_words()
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Save the file and run it in the terminal.&lt;/p&gt;

&lt;p&gt;You might first notice that this script threw an error, saying:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;KeyError: 'description'
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;One of the most important things in learning to work with code is learning to decipher error messages. If you read a little more in your terminal window, you'll see that the full message is something like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;jeriwieringa$ python my_second_script.py
Traceback (most recent call last):
  	File "my_second_script.py", line 21, in &amp;lt;module&amp;gt;
	get_words()
  	File "my_second_script.py", line 16, in get_words
	descriptions = each['sourceResource']['description']
KeyError: 'description'
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We have a traceback saying in our "get_words()" function there was an error on line 16 where we told it to save the value associated with the "description" key to the variable "descriptions". &lt;/p&gt;

&lt;p&gt;Let's see what is going. Comment out the call to "get_words" function.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;# get_words()
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now let's print the first object in the json_data list. Uncomment our print statement at the beginning of the file that pretty-prints the json. Change the 1 to 0, the save and run the file.&lt;/p&gt;

&lt;p&gt;Search for 'description' under 'sourceResource'. If you can't find it, it's because this item appears to be missing "description" information. Because the computer can't find the description, it returns an error and stops.&lt;/p&gt;

&lt;p&gt;Getting around this problem requires what is called "handling exceptions". We had expected a particular pattern in our data (that there was "description" keys nested under "sourceResource" keys) but we've encountered an exception to that general pattern. &lt;/p&gt;

&lt;p&gt;To tell the computer to keep moving if it encounters an item it cannot parse because of a KeyError, we will adjust our get_words() function as follows:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_words():
    for each in json_data:
        try:
            descriptions = each['sourceResource']['description']
            for line in descriptions:
                words = line.split()
                print words
        except KeyError:
            print "Description Missing"
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Un-comment "get_words()", save, and run the file.&lt;/p&gt;

&lt;p&gt;Our script should no longer error. If your script is spitting out letters forever, you can stop the process with "control + c" or "command + c"&lt;/p&gt;

&lt;p&gt;But, now it seems that sometime we are getting a list of letters, and sometimes a list of words. So one more adjustment is in order. We need to perform a check, where if the value of descriptions is a string, the function does one thing, and if it is not a string, it does something else. Our current code works well on the lists, so we will keep that for not strings.&lt;/p&gt;

&lt;p&gt;To check if the value in "descriptions" in a string, we can add the following:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_words():
    for each in json_data:
        try:
            descriptions = each['sourceResource']['description']
            if isinstance(descriptions, basestring):
                words = descriptions.split()
            else:
                for line in descriptions:
                    words = line.split()
            print words
        except KeyError:
            print "Description Missing"
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Looking through the information printing to our terminal window, it looks like we have correctly split out all of the words.&lt;/p&gt;

&lt;p&gt;This is an example of creating a work around when working with data that is beyond our control. What has happened is that some institutions have a description field that looks like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;'description': 'A wonderful description sentence or two giving you a summary of the item'
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;And some have used the description field like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;'description': [
    "one line of information", 
    "another line of information"
] 
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;To accommodate this, we create one process for the first case, by checking if the value is a string and a second process for the second case.&lt;/p&gt;

&lt;h3 id="adding-the-words-to-our-bag-of-words"&gt;Adding the words to our "bag of words"&lt;/h3&gt;

&lt;p&gt;The final step in creating our subset of data is to add the words into our "description_words" list.&lt;/p&gt;

&lt;p&gt;To do this, we will need to loop through the "words" list and add each word to the "description_words" list. This means another for-loop within the "try" second of our function. Also, now that we know that our words are parsing correctly, we can remove "print words".&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_words():
    for each in json_data:
        try:
            descriptions = each['sourceResource']['description']
            if isinstance(descriptions, basestring):
                words = descriptions.split()
            else:
                for line in descriptions:
                    words = line.split()
                    for word in words:
                        description_words.append(word)

        except KeyError:
            print "Description Missing"
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now to check that everything worked ok, let's run the function and print out the 1000 word in our "descriptions_words"&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;import json
from collections import Counter
import nltk
from nltk.corpus import stopwords

with open("search_results.json") as json_file:
    json_data = json.load(json_file)

#print json_data[1]
#print json.dumps(json_data[0], sort_keys=True, indent=4, separators=(',', ': '))

#print json_data[0]['sourceResource']['description']

description_words = []

def get_words():
    for each in json_data:
        try:
            descriptions = each['sourceResource']['description']
            if isinstance(descriptions, basestring):
                words = descriptions.split()
            else:
                for line in descriptions:
                    words = line.split()

            for word in words:
                description_words.append(word)

        except KeyError:
            print "Description Missing"

get_words()
print description_words[999]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id="group-challenge"&gt;Group Challenge:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Can you modify the function to also add the words of the title to our bag of words?&lt;/li&gt;
  &lt;li&gt;Can you also add the subject headings?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="what-we-learned-1"&gt;What We Learned&lt;/h3&gt;

&lt;p&gt;In this module, we learned:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to pretty-print json with Python&lt;/li&gt;
  &lt;li&gt;to identify the nested key:value pairs we want to analyze&lt;/li&gt;
  &lt;li&gt;to split a list &lt;/li&gt;
  &lt;li&gt;to trouble shoot from an error report&lt;/li&gt;
  &lt;li&gt;to handle exceptions&lt;/li&gt;
  &lt;li&gt;to check type and use an "if/else" statement&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span class="left"&gt;&lt;a href="module10.html"&gt;Previous Module&lt;/a&gt;&lt;/span&gt;
&lt;span class="right"&gt;&lt;a href="module12.html"&gt;Next Module&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Working with Local Data</title>
    <link rel="alternate" href="http://blog.url.com/modules/module10.html"/>
    <id>http://blog.url.com/modules/module10.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-26T19:56:01-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;In this module we will learn:
1. to create a new script file and load in our JSON data
2. to select data from particular fields and deal with missing data
3. to convert our JSON data to strings of text&lt;/p&gt;

&lt;p&gt;Now that we have a very large file of JSON data, we can work locally to find  patterns that we could not find using the online interface for the DPLA's holdings. Because we are interested in the language being used in order to investigate how the descriptions of 'cooking' items are gendered, our next step is to filter down that data and save it as text. In the next module, we will use the Natural Language ToolKit, a powerful Python library for working with text, to find patterns in the text data.&lt;/p&gt;

&lt;h3 id="create-a-new-script-and-load-in-our-data"&gt;1. Create a new script and load in our data&lt;/h3&gt;

&lt;p&gt;It is time to create a new script file!&lt;/p&gt;

&lt;p&gt;Go to terminal and type:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;touch my_second_script.py 
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;or on Windows: &lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;New-Item -ItemType file my_first_script.py
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;To open your new script file, type:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;open my_second_script.py
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;or on Windows:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;Start notepad++ my_first_script.py
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;First, we will need the json library again. To add this, add &lt;span class="command"&gt;import json&lt;/span&gt; to the very top of the file.&lt;/p&gt;

&lt;p&gt;The next thing is to load up the data from our "search_results.json" file.&lt;/p&gt;

&lt;p&gt;The structure for this is:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;with open("search_results.json") as json_file:
    json_data = json.load(json_file)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Here, we tell Python to "open" our "search_results.json" file and assign it to the variable "json_file". The we use the "load" method in the "json.library" to load up the data and save it as the variable "json_data". &lt;/p&gt;

&lt;p&gt;Our second script file should now look like:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;import json

with open("search_results.json") as json_file:
    json_data = json.load(json_file)    
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;To make sure this worked, let's print out one item from the json data. Work with your table to add a print statement to print the second item in the json_data list.&lt;/p&gt;

&lt;h3 id="select-the-relevant-text-data"&gt;2. Select the relevant text data&lt;/h3&gt;

&lt;p&gt;The next step is to select the fields that will be most helpful for analyzing how 'cooking' items are described across the items in the DPLA.&lt;/p&gt;

&lt;p&gt;Looking at our items, there are three main fields containing description type information for our different 'cooking' items: the title, the description, and the subject headings. &lt;/p&gt;

&lt;p&gt;Our question for these items is how, across the entire DPLA collection, the descriptions of items related to cooking are gendered. To do this, we need to do some basic text analysis, so let's save our search results in a format that makes it easy to do that: as text.&lt;/p&gt;

&lt;p&gt;To start, let's make a new function called 'get_text' that takes in our 'json_data' list:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_text(json_data):
    # Do something to each item in json_data
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Next, for each item in that array, we want to look for the 'title', the 'description', and the 'subject heading fields'. This means using another 'for loop'. &lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_text(json_data):
    for each in json_data:
        # Get the title

        # Get the description

        # Get the subject headings
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We can get the title, description, and subject headings by looking for those 'keys' within each item in our 'json_data' list. &lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_text(json_data):
    for each in json_data:
        # Get the title
        title = each['sourceResource.title']

        # Get the Description
        description = each['sourceResource.description']

        # Get the Subject Headings
        subject = each['sourceResource.subject']
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;So far so good. But what if one of these fields is missing? Programming languages are very literal - if you tell it to do something that it cannot do, it just stops and gives you an error. To see this in action, let's add a line to call the function.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;import json

with open("search_results.json") as json_file:
    json_data = json.load(json_file) 

def get_text(json_data):
    for each in json_data:
        # Get the Titles
        title = each['sourceResource.title']

        # Get the Descriptions
        description = each['sourceResource.description']

        # Get the Subject Headings
        subject = each['sourceResource.subject']

get_text(json_data)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Towards the end of the error message, you should see a line that says "KeyError: 'sourceResource.description'". This is Python telling you that it cannot find a key 'title' in one of the resources.&lt;/p&gt;

&lt;p&gt;To deal with this, we use 'try' and 'except' - we will tell the computer to try to find the keys, but if it doesn't, to assign the value to blank and move on.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_text(json_data):
    for each in json_data:
        try:
            title = each['sourceResource.title']
        except:
            title = ' '
        
        try:
            description = each['sourceResource.description']
        except:
            description = ' '

        try:
            subject = each['sourceResource.subject']
        except:
            subject = ' '
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;There are two more steps we need to get the text ready to save. The first step is to get all of the data out of lists and make sure that it is in the form of a string.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_text(json_data):
    for each in json_data:
        try:
            title = each['sourceResource.title']
            if isinstance(title, basestring):
                title = str(titles)
            else:
                for each in title:
                    title = str(each)
        except:
            title = ' '
        
        try:
            description = each['sourceResource.description']

            if isinstance(description, basestring):
                description = str(description)
            else:
                for line in description:
                    description = str(line)
        except:
            description = ' '

        try:
            subject = each['sourceResource.subject']

            if isinstance(subject, basestring):
                subject = str(subject)
            else:
                for each in subject:
                    subject = []
                    subject.append(each['name'])  
        except:
            subject = ' '
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;You might notice two odd things with this function. First, we are reusing variable names. Variables hold the last thing passed to them, so we can overwrite the value of a variable to update it as we go along. &lt;/p&gt;

&lt;p&gt;Second, we are handling the subject field differently than title and description. This is because the subject key holds an additional list, rather than just values. Work in your groups to map out what is going on in the subject section of the funciton.&lt;/p&gt;

&lt;p&gt;The last is to save this data into a text file. Similar to last time, we need to set up the file that will receive that data:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;import json

with open("search_results.json") as json_file:
    json_data = json.load(json_file) 

f = open('text_results.txt', 'a')
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The major difference here is that we are opening the file as append so that we can save each line of data as we loop, rather than storing it all and writing it all at once.&lt;/p&gt;

&lt;p&gt;Our whole file should now look like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;import json

with open("search_results.json") as json_file:
    json_data = json.load(json_file) 

f = open('text_results.txt', 'a')

def get_text(json_data):
    for each in json_data:
        try:
            title = each['sourceResource.title']
            if isinstance(title, basestring):
                title = str(titles)
            else:
                for each in title:
                    title = str(each)
        except:
            title = ' '
        
        try:
            description = each['sourceResource.description']

            if isinstance(description, basestring):
                description = str(description)
            else:
                for line in description:
                    description = str(line)
        except:
            description = ' '

        try:
            subject = each['sourceResource.subject']

            if isinstance(subject, basestring):
                subject = str(subject)
            else:
                for each in subject:
                    subject = []
                    subject.append(each['name'])  
        except:
            subject = ' '
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now, let's go back to the function and put all our pieces together into a new variable.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_text(json_data):
    for each in json_data:
        try:
            title = each['sourceResource.title']
            if isinstance(title, basestring):
                title = str(titles)
            else:
                for each in title:
                    title = str(each)
        except:
            title = ' '
        
        try:
            description = each['sourceResource.description']

            if isinstance(description, basestring):
                description = str(description)
            else:
                for line in description:
                    description = str(line)
        except:
            description = ' '

        try:
            subject = each['sourceResource.subject']

            if isinstance(subject, basestring):
                subject = str(subject)
            else:
                for each in subject:
                    subject = []
                    subject.append(each['name'])  
        except:
            subject = ' '

    data = title + '; ' + description + '; ' + ', '.join(subject) + '. \n'
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This line takes the information held in title, adds a ';' and a space, takes the information in description, add '; and a space, and finally, takes the list held in subject and smashes it together into a string, separated by a comman and a space. Finally, the '\n' adds an 'enter' the end of the line, so that the information for each item appears on a new line.&lt;/p&gt;

&lt;p&gt;The last step is to write all the information within 'data' to our file.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def get_text(json_data):
    for each in json_data:
        try:
            title = each['sourceResource.title']
            if isinstance(title, basestring):
                title = str(titles)
            else:
                for each in title:
                    title = str(each)
        except:
            title = ' '
        
        try:
            description = each['sourceResource.description']

            if isinstance(description, basestring):
                description = str(description)
            else:
                for line in description:
                    description = str(line)
        except:
            description = ' '

        try:
            subject = each['sourceResource.subject']

            if isinstance(subject, basestring):
                subject = str(subject)
            else:
                for each in subject:
                    subject = []
                    subject.append(each['name'])  
        except:
            subject = ' '

    data = title + '; ' + description + '; ' + ', '.join(subject) + '. \n'

    f.write(data.encode('utf-8'))
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Don't worry too much about the 'encode('utf-8')' bit - it forces all of the data into a consistent format and fixes a small problem of unusual characters.&lt;/p&gt;

&lt;p&gt;Now let's add a call to the function and run our code:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;import json

with open("search_results.json") as json_file:
    json_data = json.load(json_file) 

f = open('text_results.txt', 'a')

def get_text(json_data):
    for each in json_data:
        try:
            title = each['sourceResource.title']
            if isinstance(title, basestring):
                title = str(titles)
            else:
                for each in title:
                    title = str(each)
        except:
            title = ' '
        
        try:
            description = each['sourceResource.description']

            if isinstance(description, basestring):
                description = str(description)
            else:
                for line in description:
                    description = str(line)
        except:
            description = ' '

        try:
            subject = each['sourceResource.subject']

            if isinstance(subject, basestring):
                subject = str(subject)
            else:
                for each in subject:
                    subject = []
                    subject.append(each['name'])  
        except:
            subject = ' '

    data = title + '; ' + description + '; ' + ', '.join(subject) + '. \n'

    f.write(data.encode('utf-8'))

get_text(json_data)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Save and run your second python script. You should now have a text file named 'text_results.txt' in your directory. If you open that file, you should see lines of beautiful text ready for analysis.&lt;/p&gt;

&lt;p&gt;&lt;span class="left"&gt;&lt;a href="module09.html"&gt;Previous Module&lt;/a&gt;&lt;/span&gt;
&lt;span class="right"&gt;&lt;a href="module11.html"&gt;Next Module&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Writings Search Results to a File</title>
    <link rel="alternate" href="http://blog.url.com/modules/module09.html"/>
    <id>http://blog.url.com/modules/module09.html</id>
    <published>2014-09-18T20:00:00-04:00</published>
    <updated>2014-10-26T14:30:59-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;In this module we will learn:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;how to save our results to a file&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In this module, we will focus on writing the results of our functions to a text file. This gives us a local copy of the data so that we only hit the DPLA servers once for the entire collection of files.&lt;/p&gt;

&lt;h3 id="saving-our-search-results"&gt;Saving our Search Results&lt;/h3&gt;

&lt;p&gt;In order to save our search results, we first need to add a line to our code that creates the file we will save to. In your "my_first_script.py" file, right under the "all_records" variable, add:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;f = open("search_results.json", "w")
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Your file should now look like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;from dpla.api import DPLA

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking')
# print result.items[1]

all_records = []

f = open("search_results.json", "w")

def pull_records(pages, end, size):
	while(pages &amp;lt;= end):
		paged_search = dpla.search('cooking',fields=['sourceResource'], page_size=size, page=pages)
		# print paged_search.items[2]
		save_each(paged_search)
		print "finished page " + str(pages)
		pages = pages + 1

def save_each(n):
	for each in n.items:
		all_records.append(each)

pull_records(2, 3, 50)

print all_records[30]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Here you are combining a function - open("search_results.json") - with the declaration of a variable. The "open" function both opens an existing file and  creates a file if the file does not already exist on your computer. The "w" indicates that the file should be opened as "write". One thing to note about "w" - "write" gives the computer permission to overwrite the data inside the file, which is why we are opening the file once and writing the whole array at the end. If we were to write each item as we looped, we would end up with only the last item in the file. It would write and overwrite each item as it went along. If you need to write inside a loop, you can open the file as "a". This tells the computer to "append" the information to the end of the file, rather than overwrite the existing information. &lt;/p&gt;

&lt;p&gt;Python has libraries for working with JSON, but because these are more specialized libraries, they are not automatically loaded with Python. Since we need to write a JSON object, let's load that library into our file with &lt;span class="command"&gt;import json&lt;/span&gt;:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;from dpla.api import DPLA
import json

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking')
# print result.items[1]

all_records = []

f = open("search_results.json", "w")

def pull_records(pages, end, size):
	while(pages &amp;lt;= end):
		paged_search = dpla.search('cooking',fields=['sourceResource'], page_size=size, page=pages)
		# print paged_search.items[2]
		save_each(paged_search)
		print "finished page " + str(pages)
		pages = pages + 1

def save_each(n):
	for each in n.items:
		all_records.append(each)

pull_records(2, 3, 50)

print all_records[30]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now that we have a file to write to, let's create a third function, 'save_results' to write our search results to the file. Place this function after the 'pull_records' function.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;def save_results():
	data = json.dumps(all_records)
	f.write(data)
	f.close
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;What did this function do? First, we are creating a variable called "data" which we made using json.dumps, which is another function that is now available to us because we loaded the 'json' library. Next, we are taking our file variable from the first part of the module and writing all of the information contained in "data" to it. We then close the file.&lt;/p&gt;

&lt;h3 id="calling-the-write-function"&gt;Calling the "Write" Function&lt;/h3&gt;

&lt;p&gt;To run the "save_results" function, we can now call the function at the end of our file.&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;save_results()
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Our file should now look like this:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;from dpla.api import DPLA
import json

dpla = DPLA('Your-Key-Here')

# result = dpla.search('cooking')
# print result.items[1]

all_records = []

f = open("search_results.json", "w")

def pull_records(pages, end, size):
	while(pages &amp;lt;= end):
		paged_search = dpla.search('cooking',fields=['sourceResource'], page_size=size, page=pages)
		# print paged_search.items[2]
		save_each(paged_search)
		print "finished page " + str(pages)
		pages = pages + 1

def save_each(n):
	for each in n.items:
		all_records.append(each)

def save_results():
	data = json.dumps(all_records)
	f.write(data)
	f.close

pull_records(2, 3, 50)

print all_records[30]

save_results()
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Test that everything is working by running your "my_first_script.py" in terminal.&lt;/p&gt;

&lt;p&gt;Open your new "search_results.json" file and check that 200 items made it in. Close the file once you're done.&lt;/p&gt;

&lt;p&gt;Congratulations! You've written your first results file!&lt;/p&gt;

&lt;h3 id="saving-all-the-search-results"&gt;Saving all the Search Results&lt;/h3&gt;

&lt;p&gt;Finally, let's change the parameters we pass to the "pull_records" function to get all of the search results.&lt;/p&gt;

&lt;p&gt;Remember, the first number we pass to "pull_records" corresponds to the first page of search results, the second number to the last page of search results, and the third number is the number of items per page. The DPLA will cap us at 500 items per page, so let's take '500' for our third variable. We also want to start with the first page, so '1' is our first variable.&lt;/p&gt;

&lt;p&gt;To figure out the value we want for "end", we need to do a little math. If we have 10,909 items and can get 500 items a page, how many pages do we have to work through?&lt;/p&gt;

&lt;p&gt;Update your "pull_records" line to:&lt;/p&gt;

&lt;div class="highlight plaintext"&gt;&lt;table style="border-spacing: 0"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="gutter gl" style="text-align: right"&gt;&lt;pre class="lineno"&gt;1&lt;/pre&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre&gt;pull_records(1, 22, 500)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Save and run your script. &lt;/p&gt;

&lt;p&gt;Well done! You now have a local copy of all the data that we want to analyze! You have done a lot of work! Take a moment, refresh your brain with some coffee and sugar, and come back when you're ready for the last leg of the tutorial!&lt;/p&gt;

&lt;h3 id="bonus-challege-if-that-felt-too-easy"&gt;Bonus Challege (if that felt too easyâ€¦)&lt;/h3&gt;

&lt;p&gt;Can you write a function that determines the total number of pages from the search results?&lt;/p&gt;

&lt;p&gt;&lt;span class="left"&gt;&lt;a href="module09.html"&gt;Previous Module&lt;/a&gt;&lt;/span&gt;
&lt;span class="right"&gt;&lt;a href="module10.html"&gt;Next Module&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
</content>
  </entry>
</feed>
