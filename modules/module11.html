<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="" />
	  <meta name="viewport" content="width=device-width, user-scalable=no">
	
    <link href='http://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic|Nova+Square' rel='stylesheet' type='text/css'>
    <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

    <title>Analyzing the Data (Part 1)</title>

    <link href="../stylesheets/codes.css" rel="stylesheet" type="text/css" />
    <link href="../stylesheets/style.css" rel="stylesheet" type="text/css" />
  </head>

  <body class="modules modules_module11">
    <!-- HEADER -->
        <header>
				<div class="wrap">
	    <h1 id="project_title">DH Bridge</h1>
	    <h2 class="tag">Encouraging Computational Thinking and Digital Skills in the Humanities</h2>

	    <nav id="pages">
	    	<a href="/">Computational Thinking</a>
	    	<a href="http://dhbridge.org">About DH Bridge</a>
	    </nav>
	</div>
        </header> 
        <!-- MAIN CONTENT -->
        <div class="wrap">
            <div id="main">
              <article>
                		<section id="sidebar">
			<h2>Modules</h2>
			<a href="/modules/installation.html">Installation Instructions</a>

			<ol>
			<li><a href="/modules/module01.html">Working with your Computer</a></li>
			<li><a href="/modules/module02.html">Thinking about Data</a></li>
			<li><a href="/modules/module03.html">Getting Data</a></li>
			<li><a href="/modules/module04.html">Working with the API</a></li>
			<li><a href="/modules/module05.html">Writing Script Files</a></li>
			<li><a href="/modules/module06.html">Phase Two</a></li>
			<li><a href="/modules/module07.html">Using Functions and Loops</a></li>
			<li><a href="/modules/module08.html">Using While-Loops</a></li>
			<li><a href="/modules/module09.html">Writing Results to File</a></li>
			<li><a href="/modules/module10.html">Working with Local Data</a></li>
			<li><a href="/modules/module11.html">Analyzing the Data (Part 1)</a></li>
			<li><a href="/modules/module12.html">Analyzing the Data (Part 2)</a></li>
			<li><a href="/modules/module13.html">Saving Results to a File</a></li>
			</ol>
		</section>

                <section id="content">
                        <h2>
          Analyzing the Data (Part 1)
      </h2>
       <p>In this module we will:</p>

<ol>
  <li>install NLTK library</li>
  <li>use NLTK to do see patterns in the text</li>
</ol>

<h3 id="installing-nltk">Installing NLTK</h3>

<p>We are interested in the languaged used in the "description" fields across all the "cooking" items in the DPLA database. Fortunately, there is good support within Python for text analysis and one power library we can use is the Natural Language ToolKit (or NLTK).</p>

<p>To install NLTK, let's go back to our terminal and use pip.</p>

<p>Run <span class="command">pip install nltk</span>. You may need to use <span class="command">sudo pip install nltk</span>.</p>

<p>We also need to install </p>

<p>Now, go back to your file and import nltk at the top of the file.</p>

<p>There are also a number of datasets available for use with nltk. For our purposes, we will only be using the 'stopwords' dataset, but you can browse the list of all the datasets you could download and use at <a href="http://www.nltk.org/nltk_data/">http://www.nltk.org/nltk_data/</a>. </p>

<p>To download the stopwords, we are going to go back into the Python Interactive Shell. Run <span class="command">python</span>. Your terminal window should now look something like this:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4</pre></td><td class="code"><pre>Python 2.7.5 (default, Mar  9 2014, 22:15:05)
[GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; 
</pre></td></tr></tbody></table>
</div>

<p>Type <span class="command">import nltk</span> and press enter.</p>

<p>Next type <span class="command">nltk.download('stopwords')</span> and press enter.</p>

<p>Once you see </p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre>True
&gt;&gt;&gt;
</pre></td></tr></tbody></table>
</div>

<p>you have successfully downloaded the stopwords file. </p>

<p>You will also need to download a tokenizing library. Still in the Python shell, run</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>nltk.download('punkt')
</pre></td></tr></tbody></table>
</div>

<p>Again, once you see</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre>True
&gt;&gt;&gt;
</pre></td></tr></tbody></table>
</div>

<p>the download is complete.</p>

<p>You can now exit the Python Interactive Shell using <span class="command">quit()</span></p>

<h3 id="lets-start-text-mining">Let's start text mining</h3>

<p>Let's create a third script file, 'text_mining.py':</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>touch text_mining.py
</pre></td></tr></tbody></table>
</div>

<p>(or for Windows):</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>New-Item -ItemType file text_mining.py
</pre></td></tr></tbody></table>
</div>

<p>And open that script file in your text editor:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>open text_mining.py
</pre></td></tr></tbody></table>
</div>

<p>(and for Windows):</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>Start notepad++ text_mining.py
</pre></td></tr></tbody></table>
</div>

<p>Let's start by importing the nltk library and the stopwords:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords
</pre></td></tr></tbody></table>
</div>

<p>Next let's load in our text file:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3</pre></td><td class="code"><pre># Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')
</pre></td></tr></tbody></table>
</div>

<p>We can display part of our text to make sure everything is loading correctly:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords

# Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')

# Define Functions

# Make Function Calls
print cooking_text[0:20]
</pre></td></tr></tbody></table>
</div>

<p>Save a run your new script in terminal. One thing to note here is that Python treats the text as a list of letters. </p>

<p>But we want to work with the words, so let's use a function called 'tokenize' from the NLTK library. 'Tokenize' breaks our text into a list of words.</p>

<p>After 'from nltk.corpus import stopwords' in the variables section, add:
    from nltk import word_tokenize</p>

<p>Now let's comment out our print statement and transform our sentences into tokens using the 'word_tokenize' function. To see what has happened, let's also print the first 10 tokens.</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize

# Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')

cooking_tokens = word_tokenize(cooking_text)

# Define Functions

# Make Function Calls
#print cooking_text[0:20]
print cooking_tokens[0:10]
</pre></td></tr></tbody></table>
</div>

<p>Next, we need to do one more transformation on our words so that they will play nicely with NLTK. Comment out 'print cooking_tokens[0:10]' and add to the variables section after <span class="command">cooking_tokensâ€¦</span>:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>text = nltk.Text(cooking_tokens)
</pre></td></tr></tbody></table>
</div>

<p>This is a NLTK function that takes the tokens and allows us to move back and forth between a 'text view' and a 'list view' of our document.</p>

<p>Your file should now look like this:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize

# Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')

cooking_tokens = word_tokenize(cooking_text)
text = nltk.Text(cooking_tokens)

# Define Functions

# Make Function Calls
#print cooking_text[0:20]
#print cooking_tokens[0:10]
</pre></td></tr></tbody></table>
</div>

<p>The first thing we can do to get a sense of the words in our dataset is to use the 'concordance' function within NLTK. This will print all the instances of a word with the surrounding words for context.</p>

<p>After <span class="command">#print cooking_tokens[0:10]</span>, add:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>print text.concordance('cooking')
</pre></td></tr></tbody></table>
</div>

<p>Save and run your script.</p>

<p>Pretty cool! Now try changing 'cooking' to 'economics':</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>print text.concordance('economics')
</pre></td></tr></tbody></table>
</div>

<p>Try some other words to get a sense of the word usage in the 'text_results' file. You can either replace the word, or add additional print statements.</p>

<p>Another useful command is 'collocation'. This shows us all the words that tend to appear together throughout the corpus.</p>

<p>Comment out <span class="command">print text.concordance('your_last_word')</span> and add </p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>print text.collocations()
</pre></td></tr></tbody></table>
</div>

<p>Save and run your script.</p>

<p>There are probably quite a few dates and names showing up. </p>

<p>One more function that is useful for surveying our data is 'similar'. This shows us words that are used similarly to the word we give it.</p>

<p>Comment out <span class="command"> print text.collocations()</span> and add:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>print text.similar('Pot')
</pre></td></tr></tbody></table>
</div>

<p>Your script should now look like:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize

# Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')

cooking_tokens = word_tokenize(cooking_text)
text = nltk.Text(cooking_tokens)

# Define Functions

# Make Function Calls
#print cooking_text[0:20]
#print cooking_tokens[0:10]
#print text.concordance('economy')
#print text.collocations()

print text.similar('Pot')
</pre></td></tr></tbody></table>
</div>

<p>What other patterns might be interesting to know about the words used to describe objects related to 'cooking'?</p>

<p>In the next module, we will look at word counts to find the most common words used across all of the different DPLA contributors. </p>

<p><span class="left"><a href="module10.html">Previous Module</a></span>
<span class="right"><a href="module12.html">Next Module</a></span></p>



                </section>
              </article>
  			   </div>
  		</div>
  		
  		<footer>
  				<div class="wrap">
		<div id="rights">
		    <p>&copy; CC-BY 2014</p>
		    <p>The DH Bridge curriculum is supported by a microgrant from the <a href="http://ach.org/"><img src="http://dhbridge.org/images/ach-logo.png" width=50px ></a></p>
		</div>

	    <div id="contact">
	        <a href="mailto:bridgingdh@gmail.com"><i class="fa fa-paper-plane"></i></a>
	        <a href="https://twitter.com/dhbridge"><i class="fa fa-twitter"></i></a>
	        <a href="https://github.com/dhbridge/curriculum"><i class="fa fa-github"></i></a>
	    </div>
	</div>
  		</footer>

  </body>
</html>