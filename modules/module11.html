<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="" />
	  <meta name="viewport" content="width=device-width, user-scalable=no">
	
    <link href='http://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic|Nova+Square' rel='stylesheet' type='text/css'>
    <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

    <title>Analyzing the Data (Part 1)</title>

    <link href="../stylesheets/codes.css" rel="stylesheet" type="text/css" />
    <link href="../stylesheets/style.css" rel="stylesheet" type="text/css" />
  </head>

  <body class="modules modules_module11">
    <!-- HEADER -->
        <header>
				<div class="wrap">
	    <h1 id="project_title">DH Bridge</h1>
	    <h2 class="tag">Encouraging Computational Thinking and Digital Skills in the Humanities</h2>

	    <nav id="pages">
	    	<a href="/">Computational Thinking</a>
	    	<a href="http://dhbridge.org">About DH Bridge</a>
	    </nav>
	</div>
        </header> 
        <!-- MAIN CONTENT -->
        <div class="wrap">
            <div id="main">
              <article>
                		<section id="sidebar">
			<h2>Modules</h2>
			<a href="/modules/installation.html">Installation Instructions</a>
			<a href="/modules/coaches-guide.html">Coaches Guide</a>

			<ol>
			<li><a href="/modules/module01.html">Working with your Computer</a></li>
			<li><a href="/modules/module02.html">Thinking about Data</a></li>
			<li><a href="/modules/module03.html">Getting Data</a></li>
			<li><a href="/modules/module04.html">Working with the API</a></li>
			<li><a href="/modules/module05.html">Writing Script Files</a></li>
			<li><a href="/modules/module06.html">Phase Two</a></li>
			<li><a href="/modules/module07.html">Using Functions and Loops</a></li>
			<li><a href="/modules/module08.html">Using While-Loops</a></li>
			<li><a href="/modules/module09.html">Writing Results to File</a></li>
			<li><a href="/modules/module10.html">Working with Local Data</a></li>
			<li><a href="/modules/module11.html">Analyzing the Data (Part 1)</a></li>
			<li><a href="/modules/module12.html">Analyzing the Data (Part 2)</a></li>
			<li><a href="/modules/module13.html">Saving Results to a File</a></li>
			<li><a href="/modules/module14.html">Next Steps</a></li>
			</ol>
		</section>

                <section id="content">
                        <h2>
          Analyzing the Data (Part 1)
      </h2>
       <p>Up to this point, we have been focusing on molding the data we got back from the DPLA into different formats. First, we chose the part of the data we wanted to save locally and looped through all of the search result "pages" to get our large dataset. Then, because our research question involved language use and text, we transformed the data again into a format that suits the kind of analysis we want to do. Now, we get to take the results of our hard work and start to interrogate our data.</p>

<p>In this module we will:</p>

<ol>
  <li>install NLTK library</li>
  <li>use NLTK to do see patterns in the text</li>
</ol>

<h3 id="installing-nltk">1. Installing NLTK</h3>

<p>We are interested in the language used in the three fields we singled out across all the "cooking" items in the DPLA database. Fortunately, there is good support within Python for text analysis and one powerful library we can use is the Natural Language ToolKit (or NLTK).</p>

<p>To install NLTK, let's go back to our Terminal and use <code>pip</code>.</p>

<p>Run <span class="command">pip install nltk</span>. You may need to use <span class="command">sudo pip install nltk</span>  (Mac).</p>

<p>There are also a number of datasets available for use with NLTK. For our purposes, we will only be using the "stopwords" dataset. You can browse the list of all the datasets you could download and use at <a href="http://www.nltk.org/nltk_data/">http://www.nltk.org/nltk_data/</a>.</p>

<p>To download the stopwords, we are going back into the Python Interactive Interpreter. Run <span class="command">python</span>. Your Terminal window should now look something like this:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4</pre></td><td class="code"><pre>Python 2.7.5 (default, Mar  9 2014, 22:15:05)
[GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt;
</pre></td></tr></tbody></table>
</div>

<p>Type <span class="command">import nltk</span> and press Enter.</p>

<p>Next type <span class="command">nltk.download('stopwords')</span> and press Enter.</p>

<p>Once you see</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre>True
&gt;&gt;&gt;
</pre></td></tr></tbody></table>
</div>

<p>you have successfully downloaded the stopwords file.</p>

<p>You will also need to download a tokenizing library. Still in the Python interpretor, run</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>nltk.download('punkt')
</pre></td></tr></tbody></table>
</div>

<p>Again, once you see</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre>True
&gt;&gt;&gt;
</pre></td></tr></tbody></table>
</div>

<p>the download is complete.</p>

<p>You can now exit the Python Interactive Interpreter using <span class="command">quit()</span></p>

<h3 id="lets-start-text-mining">Let's Start Text Mining</h3>

<p>Let's create a third script file, "<code>text_mining.py</code>":</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>touch text_mining.py
</pre></td></tr></tbody></table>
</div>

<p>(Windows):</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>New-Item -ItemType file text_mining.py
</pre></td></tr></tbody></table>
</div>

<p>And open that script file in your text editor:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>open text_mining.py
</pre></td></tr></tbody></table>
</div>

<p>(Windows):</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>Start notepad++ text_mining.py
</pre></td></tr></tbody></table>
</div>

<p>Let's start by importing the NLTK library and the stopwords:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords
</pre></td></tr></tbody></table>
</div>

<p>Next let's load in our text file:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3</pre></td><td class="code"><pre># Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')
</pre></td></tr></tbody></table>
</div>

<p>Let's add a "<code>print</code>" command so we can display part of our text to make sure everything is loading correctly so far:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords

# Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')

# Define Functions

# Make Function Calls
print cooking_text[0:20]
</pre></td></tr></tbody></table>
</div>

<p>Save and run this script in Terminal. Let's take a look at the results. One thing to note here is that Python treats the text as a list of letters.</p>

<p>For our purposes, we want to work with the words, so let's use a function called "<code>tokenize</code>" from the NLTK library. The NLTK "<code>tokenize</code>" method has rules for splitting strings of text in to what we view as words. As the tokenizer goes through the text, it evaluates white space and punctuation, and then bundles the letters between the white space and punctuation together into "tokens". When we started, Python considered our text to be a list of letters; after tokenizing, the computer sees the text as a list of "words".</p>

<p>After "<code>from nltk.corpus import stopwords</code>" in the variables section, add:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>from nltk import word_tokenize
</pre></td></tr></tbody></table>
</div>

<p>Now let's comment out the last print statement and transform our "words" into tokens using the "<code>word_tokenize</code>" method. To see what has happened, let's also print the first <strong>10</strong> tokens.</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize

# Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')

cooking_tokens = word_tokenize(cooking_text)

# Define Functions

# Make Function Calls
#print cooking_text[0:20]
print cooking_tokens[0:10]
</pre></td></tr></tbody></table>
</div>

<p>Next, we need to do one more transformation on our words so that they will play nicely with NLTK. Comment out "<code>print cooking_tokens[0:10]</code>" and add to the variables section after <span class="command">cooking_tokensâ€¦</span>:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>text = nltk.Text(cooking_tokens)
</pre></td></tr></tbody></table>
</div>

<p>Your file should now look like this:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize

# Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')

cooking_tokens = word_tokenize(cooking_text)
text = nltk.Text(cooking_tokens)

# Define Functions

# Make Function Calls
#print cooking_text[0:20]
#print cooking_tokens[0:10]
</pre></td></tr></tbody></table>
</div>

<p>The first thing we can do to get a sense of the words in our dataset is to use the "<code>concordance</code>" method within NLTK. This will print all the instances of a word with the surrounding words for context.</p>

<p>After <span class="command">#print cooking_tokens[0:10]</span>, add:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>print text.concordance('cooking')
</pre></td></tr></tbody></table>
</div>

<p>Save and run your script.</p>

<p>Pretty cool! Now change "cooking" to "economics", save and run the script, and see what the output is:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>print text.concordance('economics')
</pre></td></tr></tbody></table>
</div>

<p>Try some other words to get a sense of the word usage in the "<code>text_results</code>" file. You can either replace the word or add additional <code>print</code> statements.</p>

<p>Another useful method is "<code>collocation</code>". This shows us all the words that tend to appear together throughout the corpus.</p>

<p>Comment out <span class="command">print text.concordance('your_last_word')</span> and add </p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>print text.collocations()
</pre></td></tr></tbody></table>
</div>

<p>Save and run your script.</p>

<p>One more method that is useful for surveying our data is "<code>similar</code>". This shows us words that are used similarly to the word we give it.</p>

<p>Comment out <span class="command"> print text.collocations()</span> and add:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>print text.similar('Pot')
</pre></td></tr></tbody></table>
</div>

<p>Your script should now look like:</p>

<div class="highlight plaintext"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21</pre></td><td class="code"><pre># Import Libraries
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize

# Set Variables
with open('text_results.txt', 'r') as file:
    cooking_text = file.read().decode('utf8')

cooking_tokens = word_tokenize(cooking_text)
text = nltk.Text(cooking_tokens)

# Define Functions

# Make Function Calls
#print cooking_text[0:20]
#print cooking_tokens[0:10]
#print text.concordance('economics')
#print text.collocations()

print text.similar('Pot')
</pre></td></tr></tbody></table>
</div>

<p>What other patterns might be interesting to know about the words used to describe objects related to "cooking"?</p>

<p>In the next module, we will look at word counts to find the most common words used across all of the different DPLA contributors.</p>

<p><span class="left"><a href="module10.html">Previous Module</a></span>
<span class="right"><a href="module12.html">Next Module</a></span></p>



                </section>
              </article>
  			   </div>
  		</div>
  		
  		<footer>
  				<div class="wrap">
		<div id="rights">
		    <p>&copy; CC-BY 2014</p>
		    <p>The DH Bridge curriculum is supported by a microgrant from the <a href="http://ach.org/"><img src="http://dhbridge.org/images/ach-logo.png" width=50px ></a></p>
		</div>

	    <div id="contact">
	        <a href="mailto:bridgingdh@gmail.com"><i class="fa fa-paper-plane"></i></a>
	        <a href="https://twitter.com/dhbridge"><i class="fa fa-twitter"></i></a>
	        <a href="https://github.com/dhbridge/curriculum"><i class="fa fa-github"></i></a>
	    </div>
	</div>
  		</footer>

  </body>
</html>